{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [collapse: code] Colab Setup (Install Dependencies)\n",
    "\n",
    "# Only run this if we are in Google Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"Installing dependencies from pyproject.toml...\")\n",
    "    # This installs the repo itself (and its dependencies)\n",
    "    !apt-get install gmsh \n",
    "    !apt-get install -qq xvfb libgl1-mesa-glx\n",
    "    !pip install pyvista -qq\n",
    "    !pip install -q \"git+https://github.com/smec-ethz/tatva-docs.git\"\n",
    "    \n",
    "    import pyvista as pv\n",
    "\n",
    "    pv.global_theme.jupyter_backend = 'static'\n",
    "    pv.global_theme.notebook = True\n",
    "    pv.start_xvfb()\n",
    "    \n",
    "    print(\"Installation complete!\")\n",
    "else:\n",
    "    import pyvista as pv\n",
    "    pv.global_theme.jupyter_backend = 'client'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed64c9",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook, we will implement a neural constitutive model. A neural constitutive model uses neural networks to represent the relationship between stress and strain in materials. This approach allows for more flexible and accurate modeling of complex material behaviors compared to traditional constitutive models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)  # Use double-precision for FEM stability\n",
    "\n",
    "import equinox as eqx\n",
    "import jax.experimental.sparse as jsp\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import scipy.sparse as sp\n",
    "from jax import Array\n",
    "from jax_autovmap import autovmap\n",
    "from tatva import Mesh, Operator, element, sparse\n",
    "from tatva_coloring import distance2_color_and_seeds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6227565e",
   "metadata": {},
   "source": [
    "## Mesh and Material Setup\n",
    "\n",
    "We start by defining the mesh and material properties for our simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab20e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [collapse: code] Mesh Generation\n",
    "\n",
    "import gmsh\n",
    "import meshio\n",
    "\n",
    "\n",
    "def create_unstructured_3d_through_hole_mesh(\n",
    "    L=10.0, H=5.0, a=3.0, mesh_size=0.8, filename=\"noem_3d_hole.msh\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates an unstructured tetrahedral mesh for a cuboid with a\n",
    "    through-hole along the Z-axis.\n",
    "\n",
    "    Parameters:\n",
    "    - L: Width/Length of the cuboid (X and Y).\n",
    "    - H: Height of the cuboid (Z-axis).\n",
    "    - a: Side of the square hole.\n",
    "    - mesh_size: Characteristic mesh size.\n",
    "    \"\"\"\n",
    "    gmsh.initialize()\n",
    "    gmsh.model.add(\"NOEM_ThroughHole\")\n",
    "    occ = gmsh.model.occ\n",
    "\n",
    "    outer_vol = occ.addBox(-L / 2, -L / 2, 0, L, L, H)\n",
    "    cutter_vol = occ.addBox(-a / 2, -a / 2, -0.1, a, a, H + 0.2)\n",
    "\n",
    "    fem_vol, _ = occ.cut([(3, outer_vol)], [(3, cutter_vol)])\n",
    "    occ.synchronize()\n",
    "\n",
    "    all_surfaces = gmsh.model.getEntities(2)\n",
    "    interface_surfaces = []\n",
    "\n",
    "    for dim, tag in all_surfaces:\n",
    "        mass_prop = occ.getCenterOfMass(dim, tag)\n",
    "        # Check if surface is on the internal walls (x or y = +/- a/2)\n",
    "        is_internal_x = (\n",
    "            np.isclose(np.abs(mass_prop[0]), a / 2, atol=1e-3)\n",
    "            and np.abs(mass_prop[1]) <= a / 2\n",
    "        )\n",
    "        is_internal_y = (\n",
    "            np.isclose(np.abs(mass_prop[1]), a / 2, atol=1e-3)\n",
    "            and np.abs(mass_prop[0]) <= a / 2\n",
    "        )\n",
    "        # Ensure it's not the top or bottom cap of the cuboid\n",
    "        is_not_cap = not np.isclose(mass_prop[2], 0, atol=1e-3) and not np.isclose(\n",
    "            mass_prop[2], H, atol=1e-3\n",
    "        )\n",
    "\n",
    "        if (is_internal_x or is_internal_y) and is_not_cap:\n",
    "            interface_surfaces.append(tag)\n",
    "\n",
    "    gmsh.model.addPhysicalGroup(3, [fem_vol[0][1]], name=\"FEM_Volume\")\n",
    "    gmsh.model.addPhysicalGroup(2, interface_surfaces, name=\"Interface\")\n",
    "\n",
    "    gmsh.option.setNumber(\"Mesh.MeshSizeMin\", mesh_size)\n",
    "    gmsh.option.setNumber(\"Mesh.MeshSizeMax\", mesh_size)\n",
    "    gmsh.model.mesh.generate(3)\n",
    "    gmsh.write(filename)\n",
    "    gmsh.finalize()\n",
    "\n",
    "    mesh = meshio.read(filename)\n",
    "    nodes = mesh.points\n",
    "    fem_elements = mesh.cells_dict[\"tetra\"]\n",
    "\n",
    "    if \"Interface\" in mesh.cell_sets_dict:\n",
    "        # Get the triangles forming the internal boundary\n",
    "        interface_tris = mesh.cells_dict[\"triangle\"][\n",
    "            mesh.cell_sets_dict[\"Interface\"][\"triangle\"]\n",
    "        ]\n",
    "        interface_node_ids = np.unique(interface_tris)\n",
    "    else:\n",
    "        interface_node_ids = np.unique(mesh.cells_dict[\"triangle\"])\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    return nodes, fem_elements, interface_node_ids\n",
    "\n",
    "\n",
    "def get_pyvista_grid(mesh, cell_type=\"quad\"):\n",
    "    if mesh.coords.shape[1] == 2:\n",
    "        pv_points = np.hstack((mesh.coords, np.zeros(shape=(mesh.coords.shape[0], 1))))\n",
    "    else:\n",
    "        pv_points = np.array(mesh.coords)\n",
    "\n",
    "    cell_type_dict = {\n",
    "        \"quad\": 4,\n",
    "        \"triangle\": 3,\n",
    "        \"tetra\": 4,\n",
    "        \"hexahedron\": 8,\n",
    "    }\n",
    "\n",
    "    pv_cells = np.hstack(\n",
    "        (\n",
    "            np.full(\n",
    "                fill_value=cell_type_dict[cell_type], shape=(mesh.elements.shape[0], 1)\n",
    "            ),\n",
    "            mesh.elements,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pv_cell_type_dict = {\n",
    "        \"quad\": pv.CellType.QUAD,\n",
    "        \"triangle\": pv.CellType.TRIANGLE,\n",
    "        \"tetra\": pv.CellType.TETRA,\n",
    "        \"hexahedron\": pv.CellType.HEXAHEDRON,\n",
    "    }\n",
    "    cell_types = np.full(\n",
    "        fill_value=pv_cell_type_dict[cell_type], shape=(mesh.elements.shape[0],)\n",
    "    )\n",
    "\n",
    "    grid = pv.UnstructuredGrid(pv_cells.flatten(), cell_types, pv_points)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [output: hide]\n",
    "\n",
    "a = 3.0\n",
    "nodes, elements, interface_idx = create_unstructured_3d_through_hole_mesh(\n",
    "    L=10.0, H=2.0, a=a, mesh_size=0.4\n",
    ")\n",
    "\n",
    "mesh = Mesh(coords=nodes, elements=elements)\n",
    "\n",
    "n_dofs_per_node = 3\n",
    "n_nodes = mesh.coords.shape[0]\n",
    "n_dofs = n_dofs_per_node * n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6bcf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = get_pyvista_grid(mesh, cell_type=\"tetra\")\n",
    "pl = pv.Plotter()\n",
    "pl.add_mesh(grid, show_edges=True)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60fd698",
   "metadata": {},
   "source": [
    "![FEM domain](../assets/plots/noem_3d_hole_mesh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349d7b8",
   "metadata": {},
   "source": [
    "We define a simple 3D bar of length $L$, width $W$, and height $H$. The bar isfixed at one end and subjected to a force at the other end. We use `Tetrahedral` elements for the mesh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80af3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tetra = element.Tetrahedron4()\n",
    "op = Operator(mesh, tetra)\n",
    "\n",
    "n_dofs_per_node = 3\n",
    "n_nodes, n_dofs = mesh.coords.shape[0], mesh.coords.shape[0] * n_dofs_per_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d52adc",
   "metadata": {},
   "source": [
    "## Defining FEM energy functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23947e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "class Material(NamedTuple):\n",
    "    \"\"\"Material properties for the elasticity operator.\"\"\"\n",
    "\n",
    "    mu: float  # Diffusion coefficient\n",
    "    lmbda: float  # Diffusion coefficient\n",
    "\n",
    "\n",
    "E = 1e4\n",
    "nu = 0.3\n",
    "mu = E / 2 / (1 + nu)\n",
    "lmbda = E * nu / (1 - 2 * nu) / (1 + nu)\n",
    "\n",
    "mat = Material(mu=mu, lmbda=lmbda)\n",
    "\n",
    "\n",
    "@autovmap(grad_u=2)\n",
    "def compute_strain(grad_u):\n",
    "    return 0.5 * (grad_u + grad_u.T)\n",
    "\n",
    "\n",
    "@autovmap(eps=2, mu=0, lmbda=0)\n",
    "def compute_stress(eps, mu, lmbda):\n",
    "    I = jnp.eye(3)\n",
    "    return 2 * mu * eps + lmbda * jnp.trace(eps) * I\n",
    "\n",
    "\n",
    "@autovmap(grad_u=2, mu=0, lmbda=0)\n",
    "def strain_energy(grad_u, mu, lmbda):\n",
    "    eps = compute_strain(grad_u)\n",
    "    sigma = compute_stress(eps, mu, lmbda)\n",
    "    return 0.5 * jnp.einsum(\"ij,ij->\", sigma, eps)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def total_fem_energy(u_flat: Array) -> float:\n",
    "    \"\"\"Compute the total energy of the system.\"\"\"\n",
    "    u = u_flat.reshape(-1, n_dofs_per_node)\n",
    "    u_grad = op.grad(u)\n",
    "    energy_density = strain_energy(u_grad, mat.mu, mat.lmbda)\n",
    "    return op.integrate(energy_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81770949",
   "metadata": {},
   "source": [
    "## Defining the Neural Constitutive Model\n",
    "\n",
    "The specific architecture employed for the neural strain energy density was a feed-forward Multi-Layer Perceptron (MLP). The network consisted of an input layer accepting the two scalar invariants $(I_1, J)$, followed by two hidden layers with 16 neurons each, and a final output layer producing the scalar\n",
    "energy value. To ensure that the second-order derivatives (Hessian) remained continuous and numerically stable, a \\texttt{softplus} activation function was  utilized across all hidden layers. This choice is critical as standard piecewise linear activations, such as \\texttt{ReLU}, yield zero second derivatives almost everywhere, leading to immediate solver divergence.\n",
    "\n",
    "\n",
    "$$\n",
    "\\psi_{\\text{total}}(I_1, J) = \\underbrace{\\left[ \\text{NN}(I_1, J; \\theta) - \\text{NN}(3, 1; \\theta) \\right]}_{\\text{Shifted Neural Potential}} + \\underbrace{\\Psi_{\\text{base}}(I_1, J)}_{\\text{Stiffness Prior}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralInclusion(eqx.Module):\n",
    "    network: eqx.nn.MLP\n",
    "    stiffness_prior: float  # Helps with initial convergence\n",
    "\n",
    "    def __init__(self, n_interface_dofs, key, stiffness_prior=1e-2):\n",
    "        self.stiffness_prior = stiffness_prior\n",
    "        self.network = eqx.nn.MLP(\n",
    "            in_size=n_interface_dofs,\n",
    "            out_size=\"scalar\",\n",
    "            width_size=64,\n",
    "            depth=3,\n",
    "            activation=jax.nn.softplus,  # Must be smooth for Hessian\n",
    "            key=key,\n",
    "        )\n",
    "\n",
    "    def __call__(self, u_interface):\n",
    "        \"\"\"\n",
    "        Computes the shifted energy: G(u) - G(0) + prior\n",
    "        u_interface: flattened array of displacements for nodes on the boundary\n",
    "        \"\"\"\n",
    "        psi_raw = self.network(u_interface)\n",
    "\n",
    "        u_zero = jnp.zeros_like(u_interface)\n",
    "        psi_0 = self.network(u_zero)\n",
    "\n",
    "        prior = 0.5 * self.stiffness_prior * jnp.sum(u_interface**2)\n",
    "\n",
    "        return (psi_raw - psi_0) + prior\n",
    "\n",
    "\n",
    "neural_operator = NeuralInclusion(\n",
    "    n_interface_dofs=len(interface_idx) * n_dofs_per_node,\n",
    "    key=jax.random.PRNGKey(0),\n",
    "    stiffness_prior=1e4, #1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c995d",
   "metadata": {},
   "source": [
    "## Coupling the domains through energies\n",
    "\n",
    "Now, we define the neural network architecture and the total strain energy density function based on the neural network defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_energy(u_flat, neural_operator):\n",
    "    u = u_flat.reshape(-1, n_dofs_per_node)\n",
    "    energy_fem = total_fem_energy(u_flat)\n",
    "\n",
    "    # Extract displacements for interface nodes\n",
    "    u_interface = u[interface_idx].flatten()\n",
    "    energy_neural = neural_operator(u_interface)\n",
    "\n",
    "    return energy_fem + energy_neural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c194d",
   "metadata": {},
   "source": [
    "## Using Coloring to compute Sparse Hessians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_pattern = sparse.create_sparsity_pattern(mesh, n_dofs_per_node=n_dofs_per_node)\n",
    "sparsity_pattern_csr = sp.csr_matrix(\n",
    "    (\n",
    "        sparsity_pattern.data,\n",
    "        (sparsity_pattern.indices[:, 0], sparsity_pattern.indices[:, 1]),\n",
    "    )\n",
    ")\n",
    "indptr = sparsity_pattern_csr.indptr\n",
    "indices = sparsity_pattern_csr.indices\n",
    "colors = distance2_color_and_seeds(\n",
    "    row_ptr=sparsity_pattern_csr.indptr,\n",
    "    col_idx=sparsity_pattern_csr.indices,\n",
    "    n_dofs=n_dofs,\n",
    ")[0]\n",
    "\n",
    "# Closure for the energy based on the NN weights\n",
    "energy_fn = eqx.Partial(total_energy, neural_operator=neural_operator)\n",
    "gradient_fn = jax.jacrev(energy_fn)\n",
    "\n",
    "K_sparse_fn = sparse.jacfwd_with_batch(\n",
    "    gradient=gradient_fn,\n",
    "    row_ptr=jnp.array(sparsity_pattern_csr.indptr),\n",
    "    col_indices=jnp.array(sparsity_pattern_csr.indices),\n",
    "    colors=jnp.array(colors),\n",
    "    color_batch_size=mesh.elements.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347d774",
   "metadata": {},
   "source": [
    "To check if the total energy at 0 deformation is zero, we can evaluate the total strain energy density function at the reference configuration where $I_1 = 3$ and $J = 1$. This ensures that the neural network's contribution is shifted  appropriately, and the stiffness prior is also evaluated at this point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457dba17",
   "metadata": {},
   "source": [
    "## Applying Boundary Conditions and Loads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundary Conditions & Solver Setup\n",
    "y_min, y_max = jnp.min(mesh.coords[:, 1]), jnp.max(mesh.coords[:, 1])\n",
    "\n",
    "\n",
    "top_nodes = jnp.where(jnp.isclose(mesh.coords[:, 1], y_max))[0]\n",
    "bottom_nodes = jnp.where(jnp.isclose(mesh.coords[:, 1], y_min))[0]\n",
    "\n",
    "applied_dofs = n_dofs_per_node * top_nodes + 1  # y-direction DOFs at the top nodes\n",
    "\n",
    "zero_dofs = jnp.concatenate(\n",
    "    [n_dofs_per_node * bottom_nodes, n_dofs_per_node * bottom_nodes + 1]\n",
    ")\n",
    "\n",
    "fixed_dofs = jnp.concatenate([applied_dofs, zero_dofs])\n",
    "\n",
    "prescribed_values = jnp.zeros(n_dofs).at[applied_dofs].set(1.0)\n",
    "\n",
    "zero_indices, one_indices = sparse.get_bc_indices(sparsity_pattern, fixed_dofs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0907cd",
   "metadata": {},
   "source": [
    "## Defining Newton Solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c88bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Collapse: code] Newton Solver with Sparse Hessian\n",
    "\n",
    "@eqx.filter_jit\n",
    "def newton_sparse_solver(\n",
    "    u,\n",
    "    fext,\n",
    "    gradient,\n",
    "    hessian_sparse,\n",
    "    fixed_dofs,\n",
    "    zero_indices,\n",
    "    one_indices,\n",
    "    indptr,\n",
    "    indices,\n",
    "):\n",
    "    fint = gradient(u)\n",
    "\n",
    "    norm_res = 1.0\n",
    "\n",
    "    tol = 1e-8\n",
    "    max_iter = 10\n",
    "\n",
    "    def solver(u, n):\n",
    "        def true_func(u):\n",
    "            fint = gradient(u)\n",
    "            residual = fext - fint\n",
    "            residual = residual.at[fixed_dofs].set(0.0)\n",
    "\n",
    "            K_sparse = hessian_sparse(u)\n",
    "            K_data_lifted = K_sparse.data.at[zero_indices].set(0)\n",
    "            K_data_lifted = K_data_lifted.at[one_indices].set(1)\n",
    "\n",
    "            du = jsp.linalg.spsolve(\n",
    "                K_data_lifted, indices=indices, indptr=indptr, b=residual\n",
    "            )\n",
    "\n",
    "            u = u.at[:].add(du)\n",
    "            return u\n",
    "\n",
    "        def false_func(u):\n",
    "            return u\n",
    "\n",
    "        fint = gradient(u)\n",
    "        residual = fext - fint\n",
    "        residual = residual.at[fixed_dofs].set(0.0)\n",
    "        norm_res = jnp.linalg.norm(residual)\n",
    "\n",
    "        jax.debug.print(\"residual={}\", norm_res)\n",
    "\n",
    "        return jax.lax.cond(norm_res > tol, true_func, false_func, u), n\n",
    "\n",
    "    u, xs = jax.lax.scan(solver, init=u, xs=jnp.arange(0, max_iter))\n",
    "\n",
    "    fint = gradient(u)\n",
    "    residual = fext - fint\n",
    "    residual = residual.at[fixed_dofs].set(0.0)\n",
    "    norm_res = jnp.linalg.norm(residual)\n",
    "\n",
    "    return u, norm_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e7363",
   "metadata": {},
   "source": [
    "## Solving the System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c3b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [output: hide]\n",
    "\n",
    "u_prev = jnp.zeros(n_dofs)\n",
    "\n",
    "fext = jnp.zeros(n_dofs) \n",
    "\n",
    "n_steps = 5\n",
    "applied_displacement = prescribed_values / n_steps  # displacement increment\n",
    "\n",
    "residual_history = []\n",
    "\n",
    "print(\"Starting Neural Constitutive Solver...\")\n",
    "for i in range(n_steps):  # Newton iterations\n",
    "    u_prev = u_prev.at[fixed_dofs].add(applied_displacement[fixed_dofs])\n",
    "\n",
    "    u_new, rnorm = newton_sparse_solver(\n",
    "        u_prev,\n",
    "        fext,\n",
    "        gradient_fn,\n",
    "        K_sparse_fn,\n",
    "        fixed_dofs,\n",
    "        zero_indices,\n",
    "        one_indices,\n",
    "        indptr,\n",
    "        indices,\n",
    "    )\n",
    "\n",
    "    residual_history.append(rnorm)\n",
    "\n",
    "    u_prev = u_new\n",
    "\n",
    "    print(f\"Iteration {i}: Residual Norm = {rnorm:.4e}\")\n",
    "\n",
    "u_sol = u_prev.reshape(n_nodes, n_dofs_per_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f05e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Collapse: code] Visualization of Results\n",
    "\n",
    "grid = pv.UnstructuredGrid(\n",
    "    np.hstack((np.full((mesh.elements.shape[0], 1), 4), mesh.elements)).flatten(),\n",
    "    np.full(mesh.elements.shape[0], pv.CellType.TETRA),\n",
    "    np.array(mesh.coords),\n",
    ")\n",
    "\n",
    "pl = pv.Plotter()\n",
    "\n",
    "grad_u = op.grad(u_sol).squeeze()\n",
    "strains = compute_strain(grad_u)\n",
    "stresses = compute_stress(strains, mat.mu, mat.lmbda)\n",
    "\n",
    "\n",
    "grid[\"u\"] = np.array(u_sol)\n",
    "grid[\"sigma_yy\"] = stresses[:, 1, 1].flatten()\n",
    "\n",
    "warped = grid.warp_by_vector(\"u\", factor=4.0)\n",
    "pl.add_mesh(warped, show_edges=False, scalars=\"u\", component=0, cmap=\"managua\", show_scalar_bar=False)\n",
    "pl.view_isometric()\n",
    "pl.screenshot(\"../assets/plots/neural_soft_inclusion_deformed_mesh.png\", transparent_background=True)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6b484b",
   "metadata": {},
   "source": [
    "![Neural operator element with soft inclusion](../assets/plots/neural_soft_inclusion_deformed_mesh.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tatva-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
