{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b1cde5",
   "metadata": {},
   "source": [
    "# Building Stiffness Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [collapse: code] Colab Setup (Install Dependencies)\n",
    "\n",
    "# Only run this if we are in Google Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"Installing dependencies from pyproject.toml...\")\n",
    "    # This installs the repo itself (and its dependencies)\n",
    "    !apt-get install gmsh \n",
    "    !apt-get install -qq xvfb libgl1-mesa-glx\n",
    "    !pip install pyvista -qq\n",
    "    !pip install -q \"git+https://github.com/smec-ethz/tatva-docs.git\"    \n",
    "    print(\"Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de33c4d",
   "metadata": {},
   "source": [
    "\n",
    "## Problem\n",
    "\n",
    "In finite element analysis, the tangent stiffness matrix (Hessian) $\\mathbf{K}$ is typically **sparse**. A node only interacts with its immediate neighbors, meaning most entries in $\\mathbf{K}$ are zero. However, standard automatic differentiation (AD) in JAX (`jax.jacfwd` or `jax.jacrev`) is unaware of this sparsity. It attempts to recover the full dense matrix by evaluating the Jacobian-Vector Product (JVP) once for every degree of freedom.\n",
    "\n",
    "For a mesh with $N$ degrees of freedom:\n",
    "\n",
    "* **Naive AD Cost:** $N \\times t_{\\text{residual}}$ (Prohibitive for large $N$)\n",
    "* **Memory:** $O(N^2)$ (Explodes quickly)\n",
    "\n",
    "We need a way to compute **only the non-zero entries** of $\\mathbf{K}$ efficiently, ideally in constant time with respect to the mesh size.\n",
    "\n",
    "## Solution\n",
    "\n",
    "`tatva` provides 2 ways to build a computationally efficient stiffness matrix using the energy functional.\n",
    "\n",
    "- **Matrix-free operator** using Jacobian-vector product.\n",
    "- **Sparse stiffness matrix** using sparse differentiation.\n",
    "\n",
    "\n",
    "Below we demonstrate the two approaches, we use a pseudo energy functional that is defined for a given mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83d62edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)  # use double-precision\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import scipy.sparse as sp\n",
    "from tatva import sparse, Mesh\n",
    "\n",
    "mesh = Mesh.unit_square(n_x=1, n_y=1,  type=\"triangle\", dim=2)\n",
    "n_dofs_per_node = 2\n",
    "n_dofs = mesh.coords.shape[0] * n_dofs_per_node\n",
    "\n",
    "\n",
    "def energy_fn(u, delta):\n",
    "    # Placeholder for the actual energy function\n",
    "    return jnp.sum(u**2) + delta * jnp.sum(u)\n",
    "\n",
    "delta_current = 1.0  # Example parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b872eb30",
   "metadata": {},
   "source": [
    "## Matrix-free Operator\n",
    "\n",
    "Since we have the energy functional, we can compute the Jacobian-vector product (JVP) $\\mathbf{K}\\mathbf{v}$ directly without ever forming $\\mathbf{K}$. We can use [`jax.jvp`](https://docs.jax.dev/en/latest/_autosummary/jax.jvp.html) to compute the Jacobian-vector product.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "222755a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_vector_product(u, v, delta):\n",
    "    \"\"\"\n",
    "    Computes (Hessian of Energy at u) * v. It is equivalent to: jvp( jacrev(energy)(u), v ).\n",
    "    Args:\n",
    "        u: Current solution (shape: [n_dofs])\n",
    "        v: Vector to multiply with the Hessian (shape: [n_dofs])\n",
    "        delta: Additional parameter for the energy function\n",
    "    Returns:\n",
    "        The product of the Hessian of the energy function at u with the vector v (shape: [n_dofs])\n",
    "    \"\"\"\n",
    "    return jax.jvp(jax.jacrev(energy_fn), (u, delta), (v, delta))[1]\n",
    "\n",
    "\n",
    "delta_f = jacobian_vector_product(u=jnp.zeros(n_dofs), v=jnp.ones(n_dofs), delta=delta_current)\n",
    "\n",
    "# or can be passed directly to iterative solvers like jax.scipy.sparse.linalg.cg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35716c01",
   "metadata": {},
   "source": [
    "Some of the examples that use **Matrix-Free Operators** are\n",
    "\n",
    "- [Linear elasticity](examples/linear_elasticity.ipynb)\n",
    "- [Contact between deformable bodies](examples/contact_3d.ipynb)\n",
    "- [Fracture using Cohesive Traction Law](examples/fracture_quasistatic_3d.ipynb)\n",
    "- [Multiphysical Fracture using Phasefield](examples/thermal_shock_fracture.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3025fc",
   "metadata": {},
   "source": [
    "## Sparse Differentiation\n",
    "\n",
    "[`tatva.sparse`](api/tatva.sparse.md#sparse) provides a sparse differentiation engine that reduces the cost from $O(N)$ to $O(c)$, where $c$ is the \"chromatic number\" of the mesh (typically small and constant, e.g., ~10-20 for 2D meshes).\n",
    "\n",
    "The process has three steps:\n",
    "\n",
    "-  **Sparsity Pattern:** Identify the non-zero structure.\n",
    "-  **Coloring:** Group non-interacting DOFs.\n",
    "-  **Differentiation:** Compute the matrix in batches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be62ec74",
   "metadata": {},
   "source": [
    "\n",
    "### Sparsity Pattern\n",
    "\n",
    "First, we analyze the mesh connectivity to determine which DOFs interact. [`create_sparsity_pattern`](api/tatva.sparse.md#tatva.sparse.create_sparsity_pattern) returns the indices of the non-zero entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "631489a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 56 non-zeros\n"
     ]
    }
   ],
   "source": [
    "# Extract sparsity topology from the mesh\n",
    "sparsity_pattern = sparse.create_sparsity_pattern(\n",
    "    mesh,\n",
    "    n_dofs_per_node=n_dofs_per_node\n",
    ")\n",
    "\n",
    "# Convert to Scipy CSR format for efficient indexing and later use\n",
    "sparsity_pattern_csr = sp.csr_matrix(\n",
    "    (\n",
    "        sparsity_pattern.data,\n",
    "        (sparsity_pattern.indices[:, 0], sparsity_pattern.indices[:, 1]),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Sparsity: {sparsity_pattern_csr.nnz} non-zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36c2e9",
   "metadata": {},
   "source": [
    "!!! info \"Sparsity Pattern\"\n",
    "\n",
    "    In `tatva` we provide a few functionalities to generate sparsity patetrn for some specific problem. \n",
    "    \n",
    "    - for a single physical field problem, [`sparse.create_sparsity_pattern`](api/tatva.sparse.md#tatva.sparse.create_sparsity_pattern)\n",
    "    - for KKT problems, [`sparse.create_sparsity_pattern_KKT`](api/tatva.sparse.md#tatva.sparse.create_sparsity_pattern_KKT)\n",
    "    - for reduced system via condensation  [`sparse.reduce_sparsity_pattern`](api/tatva.sparse.md#tatva.sparse.reduce_sparsity_pattern)\n",
    "    - for periodic problem [`sparse.create_sparsity_pattern_master_slave`](api/tatva.sparse.md#tatva.sparse.create_sparsity_pattern_master_slave)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f02412",
   "metadata": {},
   "source": [
    "### Graph Coloring\n",
    "\n",
    "We partition the degrees of freedom into independent sets (colors). Two DOFs share the same color **only if** they do not share an edge in the sparsity graph (Distance-1) and do not share a common neighbor (Distance-2). This ensures that when we perturb all DOFs of \"Color A\" simultaneously, their contributions to the Hessian do not overlap.\n",
    "\n",
    "!!! info \"Coloring Algorithm\"\n",
    "    \n",
    "    We use `tatva_coloring` library to generate colors from a sparsity pattern and take the first return value which is the colors. The implemented coloring algorithm is a naive greedy-algorithm. One can easily use other coloring libraries such as [pysparsematrixcolorings](https://github.com/gdalle/pysparsematrixcolorings) to use advanced coloring algorithms which are efficient as they generate less number of colors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94cc9f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of colors required: 8\n"
     ]
    }
   ],
   "source": [
    "from tatva_coloring import distance2_color_and_seeds\n",
    "\n",
    "colors = distance2_color_and_seeds(\n",
    "    row_ptr=sparsity_pattern_csr.indptr,\n",
    "    col_idx=sparsity_pattern_csr.indices,\n",
    "    n_dofs=n_dofs,\n",
    ")[0]\n",
    "\n",
    "print(f\"Number of colors required: {jnp.max(colors) + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab4cc5c",
   "metadata": {},
   "source": [
    "\n",
    "### Sparse Differentiation\n",
    "\n",
    "Finally, we use [`sparse.jacfwd`](api/tatva.sparse.md#tatva.sparse.jacfwd). This function automatically:\n",
    "-  Perturbs the input $\\boldsymbol{u}$ using the color groups.\n",
    "-  Evaluates the gradient efficiently (Batched JVPs).\n",
    "-  Reconstructs the values into the correct sparse matrix locations.\n",
    "\n",
    "\n",
    "!!! Info\n",
    "\n",
    "    We use our own implementation of sparse differentiation to make it scalable for large problems. But one can use libraries such as [sparsejac](https://github.com/mfschubert/sparsejac) which has been an source of inspiration for our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_fn = jax.jacrev(energy_fn, argnums=0)  # Gradient with respect to u\n",
    "\n",
    "# differentiate the residual using the sparsity information\n",
    "K_sparse_fn = sparse.jacfwd(\n",
    "    gradient=gradient_fn,\n",
    "    row_ptr=jnp.array(sparsity_pattern_csr.indptr),\n",
    "    col_indices=jnp.array(sparsity_pattern_csr.indices),\n",
    "    colors=jnp.array(colors),\n",
    "    color_batch_size=10, # Batch size for evaluating the element routine\n",
    ")\n",
    "\n",
    "u_current = jnp.zeros(n_dofs)  # Example input\n",
    "K_sparse = K_sparse_fn(u_current, delta_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d0173",
   "metadata": {},
   "source": [
    "!!! Info\n",
    "\n",
    "    The above function `K_sparse_fn` needs to be created only once given the sparsity pattern is not changing. Once created one can use te generated function within the simulation loop. \n",
    "    If the energy function takes additional arguments for example history parameters then the generated `K_sparse_fn` also takes the same arguments. \n",
    "\n",
    "\n",
    "### Computing **K** at fixed additional parameters \n",
    "\n",
    "Sometimes we need to evalues $\\mathbf{K}$ at fixed values for additinal arguments but updated values of $\\boldsymbol{u}$. For example, in Newton-Raphson or Staggered solvers. Use `partial` from `functools` to freeze some argument values. For example\n",
    "\n",
    "```python\n",
    "from functools import partial\n",
    "\n",
    "K_sparse_partial = jax.jit(partial(K_sparse_fn, delta=delta_current))\n",
    "\n",
    "# newton iteration\n",
    "for i in range(iter):\n",
    "    ...\n",
    "    # call K_sparse_partial with just u\n",
    "    K_sparse = K_sparse_partial(u_new)\n",
    "    ...\n",
    "\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fad39a",
   "metadata": {},
   "source": [
    "Some of the examples that use **sparse differentiation** are:\n",
    "\n",
    "- [Periodic Boundary Conditions using Lagrange Multiplier](examples/homogenization_periodic.ipynb)\n",
    "- [Neural Constitutive Law](examples/ncm_metamaterial.ipynb)\n",
    "- [Neural Operator Element method](examples/neural_operator_method_3d.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29d26ca",
   "metadata": {},
   "source": [
    "\n",
    "!!! tip\n",
    "\n",
    "    For extremely large problems, even storing the sparse matrix indices might be too memory-intensive. Then one should use **Matrix-free** approach.\n",
    "    Also, for the problems where finding the sparsity pattern is difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd112d67",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tatva-docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
